# Multi-Model Testing Configuration
#
# This file defines the LLM models to test in multi-model comparison mode.
# Each model will be evaluated across three modes: vanilla, web, and MARRVEL-MCP.
#
# Provider Support:
#   - bedrock: AWS Bedrock (uses boto3)
#   - openai: OpenAI direct API
#   - openrouter: OpenRouter API (uses OpenAI-compatible API)
#   - ollama: Ollama local/remote (uses OpenAI-compatible API)
#
# Usage:
#   python evaluate_mcp.py --multi-model
#
# The result will show a grid comparing all models across all modes.


models:
  # OpenRouter - Anthropic Claude models

  # OpenRouter - Meta LLaMA models
  - name: "LLaMA 3.2 3B Instruct"
    id: "meta-llama/llama-3.2-3b-instruct"
    provider: "openrouter"
    enabled: false
    skip_vanilla: true
    description: "Meta LLaMA 3.2 3B Instruct via OpenRouter ($0.03/$0.06 per 1M tokens)"

  - name: "LLaMA 3.1 8B Instruct"
    id: "meta-llama/llama-3.1-8b-instruct"
    provider: "openrouter"
    enabled: true
    skip_vanilla: true
    description: "Meta LLaMA 3.1 8B Instruct via OpenRouter ($0.02/$0.03 per 1M tokens)"

  # OpenRouter - Qwen models
  - name: "Qwen 3 14B"
    id: "qwen/qwen3-14b"
    provider: "openrouter"
    enabled: true
    skip_vanilla: true
    description: "Qwen 3 14B via OpenRouter ($0.05/$0.22 per 1M tokens)"

  - name: "GPT OSS 20B"
    id: "openai/gpt-oss-20b"
    provider: "openrouter"
    enabled: false
    skip_vanilla: true
    skip_web_search: true
    description: "GPT OSS 20B via OpenRouter ($0.03/$0.14 per 1M tokens)"

  # OpenRouter - OpenAI OSS models
  - name: "GPT OSS 120B"
    id: "openai/gpt-oss-120b"
    provider: "openrouter"
    enabled: true
    skip_vanilla: true
    skip_web_search: true
    description: "GPT OSS 120B via OpenRouter ($0.04/$0.22 per 1M tokens)"

  - name: "Claude 3.5 Sonnet v2 (Oct 2024)"
    id: "us.anthropic.claude-3-5-sonnet-20241022-v2:0"
    provider: "bedrock"
    enabled: false
    skip_web_search: true
    description: "Anthropic Claude 3.5 Sonnet v2 October 2024 via AWS Bedrock"

  # Claude 3.5 Haiku
  - name: "Claude 3.5 Haiku"
    id: "us.anthropic.claude-3-5-haiku-20241022-v1:0"
    provider: "bedrock"
    enabled: true
    skip_web_search: true
    description: "Anthropic Claude 3.5 Haiku via AWS Bedrock"

  - name: "Claude 4.0 Sonnet"
    id: "us.anthropic.claude-sonnet-4-20250514-v1:0"
    provider: "bedrock"
    enabled: true
    skip_web_search: true
    description: "Anthropic Claude 4.0 Sonnet via AWS Bedrock"

# Configuration options
config:
  # Only test models where enabled: true
  only_enabled: true

  # Timeout per model test (seconds)
  timeout: 60

  # Whether to cache results per model
  use_cache: false

  # Evaluator model configuration (used for grading/classifying test responses)
  # This model evaluates all test responses for consistent comparison across models
  # If not specified, falls back to environment variables EVALUATION_MODEL and EVALUATION_PROVIDER
  evaluator:
    provider: "bedrock"
    model: "us.anthropic.claude-sonnet-4-20250514-v1:0"
